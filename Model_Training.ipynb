{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1ysy4TNqFPhF89ZulVE3Jul4STbVeo5NY",
      "authorship_tag": "ABX9TyOREL8P/qZN4o4uVtDOi38R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ypsGh-xTJZ",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition - Model Training\n",
        "\n",
        "If you are new to this, I suggest you to read [Data Preprocessing File](https://github.com/akash1309/Named-Entity-Recognition/blob/master/Data_Preprocessing.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqaBq7zzKlav",
        "colab_type": "text"
      },
      "source": [
        "## 1) Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbp5bOM9xLPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "43c011df-61e1-48c2-cd52-6741d44828dd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import spacy\n",
        "import nltk\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "import seaborn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkXeJ1PdLNCq",
        "colab_type": "text"
      },
      "source": [
        "## 2) Loading the text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB-kKnHdLQ0u",
        "colab_type": "text"
      },
      "source": [
        "- In NLP, we have `text` as input and our machine can't understand texts. So, our first step is to make a dictionary which stores a `numerical value` corresponding the a `word`.\n",
        "\n",
        "- In NLP applications, a sentence is represented by the sequence of indices of the words in the sentence. \n",
        "      For example if our vocabulary is {'is':1, 'John':2, 'Where':3, '.':4, '?':5} \n",
        "      then the sentence “Where is John ?” is represented as [3,1,2,5]. \n",
        "\n",
        "- We read the words.txt file and populate our vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvFnuuDJKv9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for words.txt\n",
        "\n",
        "word_filepath = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/words.txt'\n",
        "word_vocab = {}\n",
        "with open(word_filepath,'r') as f:\n",
        "\n",
        "  for i,word in enumerate(f.read().splitlines()):\n",
        "    word_vocab[word] = i\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iw1VySoMau3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1s1DQqiM-Xh",
        "colab_type": "text"
      },
      "source": [
        "In a similar way, we load a mapping `tag_map` from our `labels` from `tags.txt` to indices. Doing so gives us indices for labels in the range `[0,1,...,NUM_TAGS-1]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPhlpZ8zMcvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for tags.txt\n",
        "\n",
        "tags_filepath = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/tags.txt'\n",
        "tag_vocab = {}\n",
        "\n",
        "with open(tags_filepath,'r') as f:\n",
        "\n",
        "  for i,word in enumerate(f.read().splitlines()):\n",
        "    tag_vocab[word] = i "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMiy2FjsOaJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "54d8ab2b-135c-4690-925e-673f99433871"
      },
      "source": [
        "tag_vocab"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-art': 8,\n",
              " 'B-geo': 1,\n",
              " 'B-gpe': 2,\n",
              " 'B-org': 5,\n",
              " 'B-per': 3,\n",
              " 'B-tim': 7,\n",
              " 'I-art': 9,\n",
              " 'I-geo': 4,\n",
              " 'I-org': 6,\n",
              " 'I-per': 10,\n",
              " 'O': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQeeHkFBOulb",
        "colab_type": "text"
      },
      "source": [
        "In addition to words read from English sentences, `words.txt` contains two special tokens: an `UNK` token to represent any word that is not present in the vocabulary, and a `PAD` token that is used as a filler token at the end of a sentence when one batch has sentences of unequal lengths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61n0zQtDO7ED",
        "colab_type": "text"
      },
      "source": [
        "We are now ready to load our data. We read the sentences in our dataset (either train, validation or test) and convert them to a sequence of indices by looking up the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTPRjHWUSeJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for sentences.txt file \n",
        "\n",
        "def encode_sentences(file_path):\n",
        "\n",
        "  sentences = []\n",
        "  \n",
        "  with open(file_path) as f:\n",
        "    for sent in f.read().splitlines():\n",
        "      #replace each token by its index if it is in vocab else use index of UNK\n",
        "      s = []\n",
        "      for token in sent.split(' '):\n",
        "        if token in word_vocab:\n",
        "          s.append(word_vocab[token])\n",
        "        else:\n",
        "          s.append(word_vocab['UNK'])  \n",
        "\n",
        "      sentences.append(s)\n",
        "\n",
        "  return sentences    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vamBvnjoTljc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for labels.txt file \n",
        "\n",
        "def encode_labels(file_path):\n",
        "\n",
        "  labels = []\n",
        "  with open(file_path) as f:\n",
        "    for sentence in f.read().splitlines():\n",
        "      l = [tag_vocab[label] for label in sentence.split(' ')]\n",
        "      labels.append(l)\n",
        "\n",
        "  return labels   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OP72mIAOe1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For train file\n",
        "\n",
        "train_file_sentences = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/train/sentences.txt'\n",
        "train_file_labels = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/train/labels.txt'\n",
        "\n",
        "train_sentences = encode_sentences(train_file_sentences)\n",
        "train_labels = encode_labels(train_file_labels)\n",
        "\n",
        "# print(train_sentences)\n",
        "# print(\"-------------\")\n",
        "# print(train_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCK8kw0bR-FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For validation file\n",
        "\n",
        "val_file_sentences = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/val/sentences.txt'\n",
        "val_file_labels = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/val/labels.txt'\n",
        "\n",
        "val_sentences = encode_sentences(val_file_sentences)\n",
        "val_labels = encode_labels(val_file_labels)\n",
        "\n",
        "# print(val_sentences)\n",
        "# print(\"-------------\")\n",
        "# print(val_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6byqmJFYSI6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For test file\n",
        "\n",
        "test_file_sentences = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/test/sentences.txt'\n",
        "test_file_labels = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/test/labels.txt'\n",
        "\n",
        "test_sentences = encode_sentences(test_file_sentences)\n",
        "test_labels = encode_labels(test_file_labels)\n",
        "\n",
        "# print(test_sentences)\n",
        "# print(\"-------------\")\n",
        "# print(test_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U6MLGtZSRpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
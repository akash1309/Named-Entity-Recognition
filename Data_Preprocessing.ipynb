{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6toKIHcOkbB",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition\n",
        "\n",
        "Brief Introduction : \n",
        "- https://en.wikipedia.org/wiki/Named-entity_recognition\n",
        "- https://towardsdatascience.com/contextual-embeddings-for-nlp-sequence-labeling-9a92ba5a6cf0\n",
        "- https://cs230.stanford.edu/blog/namedentity/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMrhMKPiRRW0",
        "colab_type": "text"
      },
      "source": [
        "### 1) Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc9xq96ZOdoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import nltk\n",
        "import spacy\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TQizsawRpKP",
        "colab_type": "text"
      },
      "source": [
        "### 2) Reading input file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLkcBab7fbZf",
        "colab_type": "code",
        "outputId": "92f3a3a3-e510-4b47-dadf-ebbfb21a9dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdecqOCkRmRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ner_dataset does not have utf-8 encoding,running this line will give errors\n",
        "# uncomment it to see errors\n",
        "# df = pd.read_csv('drive/My Drive/Datasets/ner_dataset.csv',encoding='utf-8') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCM9lCUUUh_J",
        "colab_type": "text"
      },
      "source": [
        "Solving the above error : https://stackoverflow.com/questions/21504319/python-3-csv-file-giving-unicodedecodeerror-utf-8-codec-cant-decode-byte-err\n",
        "\n",
        "- Here, it can be noted that our file has an encoding of `windows-1252` . So, we will use this only.\n",
        "- Source where I found about this file's encoding : https://github.com/cs230-stanford/cs230-code-examples/blob/master/pytorch/nlp/build_kaggle_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmqgfTfgTBiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/Pytorch_DataSet/Named Entity Recognition/ner_dataset.csv',encoding='windows-1252')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxA7rLSzUgBD",
        "colab_type": "code",
        "outputId": "28b2c6c9-5f10-4039-c038-2c80bad6851c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k75-kqCG8m2u",
        "colab_type": "code",
        "outputId": "3dc79ca2-0e2e-4590-929d-c7b285b4d545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "#printing rows from 60 to 120\n",
        "df.loc[90:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>NaN</td>\n",
              "      <td>annual</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>NaN</td>\n",
              "      <td>conference</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Britain</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NaN</td>\n",
              "      <td>'s</td>\n",
              "      <td>POS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NaN</td>\n",
              "      <td>ruling</td>\n",
              "      <td>VBG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Labor</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Party</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>NaN</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #        Word  POS    Tag\n",
              "90         NaN         the   DT      O\n",
              "91         NaN      annual   JJ      O\n",
              "92         NaN  conference   NN      O\n",
              "93         NaN          of   IN      O\n",
              "94         NaN     Britain  NNP  B-geo\n",
              "95         NaN          's  POS      O\n",
              "96         NaN      ruling  VBG      O\n",
              "97         NaN       Labor  NNP  B-org\n",
              "98         NaN       Party  NNP  I-org\n",
              "99         NaN          in   IN      O\n",
              "100        NaN         the   DT      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvrVIJw3Izjp",
        "colab_type": "code",
        "outputId": "952b524f-f3a5-432c-b73d-5493d7c4bac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1048575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdWYvcGNI3PY",
        "colab_type": "code",
        "outputId": "60bfcdb1-01a2-42ad-c99a-cb57155816d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47959</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>47959</td>\n",
              "      <td>35178</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sentence: 47654</td>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>52573</td>\n",
              "      <td>145807</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Sentence #     Word      POS      Tag\n",
              "count             47959  1048575  1048575  1048575\n",
              "unique            47959    35178       42       17\n",
              "top     Sentence: 47654      the       NN        O\n",
              "freq                  1    52573   145807   887908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KilGCtF9UEGv",
        "colab_type": "code",
        "outputId": "56aa4776-7e60-49be-b3f0-c22e45040f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count    Dtype \n",
            "---  ------      --------------    ----- \n",
            " 0   Sentence #  47959 non-null    object\n",
            " 1   Word        1048575 non-null  object\n",
            " 2   POS         1048575 non-null  object\n",
            " 3   Tag         1048575 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 32.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unja1eRHaFFv",
        "colab_type": "text"
      },
      "source": [
        "## 3) Forming sentences and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQbQH_UZVESW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = df['Word'].tolist()\n",
        "sentences = ' '.join(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWpUUJKrFV1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SITgrZeOJDVe",
        "colab_type": "text"
      },
      "source": [
        "On seeing this dataset, we have to convert it into 2 text files, one contains sentences and other contains labels.\n",
        "\n",
        "Example :\n",
        "\n",
        "      sentences.txt\n",
        "\n",
        "      John lives in New York\n",
        "      Where is John ?\n",
        "\n",
        "      labels.txt\n",
        "      \n",
        "      B-PER O O B-LOC I-LOC\n",
        "      O O B-PER O"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGEnRrGFJmik",
        "colab_type": "text"
      },
      "source": [
        "On having a closer look at dataset, we know that first columns corresponds to sentence numbers and we can use them as if we work on string `sentences` that we have to consider every punctuation for sentence ending if we write our own code. But it can be done using nltk or spacy sentences option,but then we will have another problem as tagging these sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O79q-GJLIs-G",
        "colab_type": "code",
        "outputId": "a65f35fa-18b6-479e-87e9-25b92d8d1373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Sentence #', 'Word', 'POS', 'Tag'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIabGuF9KxlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgFZNzViLWOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag = ' '.join(df['Tag'].tolist())\n",
        "#tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmUDAB7dLm5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR_k5_tkNfUw",
        "colab_type": "code",
        "outputId": "437a5ec2-a9fe-440e-a359-a73c018a3c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#doc = nlp(sentences)\n",
        "\"\"\"\n",
        "Above line will show text limit error : \n",
        "\n",
        "ValueError: [E088] Text of length 6053799 exceeds maximum of 1000000. \n",
        "The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input.\n",
        "This means long texts may cause memory allocation errors. \n",
        "If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit.\n",
        "The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\n",
        "\n",
        "Uncomment it to see the error.\n",
        "\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nAbove line will show text limit error : \\n\\nValueError: [E088] Text of length 6053799 exceeds maximum of 1000000. \\nThe v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input.\\nThis means long texts may cause memory allocation errors. \\nIf you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit.\\nThe limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.\\n\\nUncomment it to see the error.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7LKWsLEOkrz",
        "colab_type": "text"
      },
      "source": [
        "- Here we can see that using sentences string wont help us and it can, but then we have to split the sentences that can have errors.\n",
        "- Let's try and think on working on dataframe only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sgI5PuBS1MA",
        "colab_type": "text"
      },
      "source": [
        "Solution of above error: https://stackoverflow.com/questions/57231616/valueerror-e088-text-of-length-1027203-exceeds-maximum-of-1000000-spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr56ND6sSt5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nlp.max_length = 6053799"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mYD7KiYSz56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#doc = nlp(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5_odqXVTa7M",
        "colab_type": "text"
      },
      "source": [
        "- It will take a lot of time and your ram will crash automatically.\n",
        "\n",
        "- Lets work on dataframe only.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ie2c_scEAk-",
        "colab_type": "text"
      },
      "source": [
        "Before working on dataset lists, \n",
        "- Lets learn about lists append() and += function and \n",
        "- Difference between list() and [] which is used to initialize a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEvC7mwyD_PN",
        "colab_type": "code",
        "outputId": "48399dff-5b37-4e83-d002-5b49bc98a2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "list1 = [].append([2]) # This will return an empty list only, as append() function return None as function return Values\n",
        "print(list1)\n",
        "\n",
        "list2 = []     # correct way\n",
        "list2.append([1,2])\n",
        "list2.append([3,4])\n",
        "print(list2)  \n",
        "\n",
        "list3 = [] + [1,2,3] + [2,3,4]  # this add function will always create only one list.\n",
        "print(list3)\n",
        "\n",
        "\"\"\"\n",
        "list() is a function call, and [] a literal:        \n",
        "Use the second form. It's more Pythonic, and it's probably faster \n",
        "(since it doesn't involve loading and calling a separate funciton).\n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "[[1, 2], [3, 4]]\n",
            "[1, 2, 3, 2, 3, 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nlist() is a function call, and [] a literal:        \\nUse the second form. It's more Pythonic, and it's probably faster \\n(since it doesn't involve loading and calling a separate funciton).\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slk7Yq5NjxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "0168bb78-fd5a-4972-e542-c53d99e06e5e"
      },
      "source": [
        "sents = []\n",
        "tags = []\n",
        "s = []\n",
        "t = []\n",
        "first = True  \n",
        "# This is used because for initial sentence empty list is added which is creating problems.\n",
        "#Therefore to remove that first addition of empty list we are checking for first sentence and not adding it.\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "  sent = row['Sentence #']\n",
        "  word = row['Word']\n",
        "  tag = row['Tag']\n",
        "   \n",
        "  if type(sent) == type('abc'):\n",
        "    if first != True:\n",
        "      sents.append(s.copy())  # https://stackoverflow.com/questions/2612802/how-to-clone-or-copy-a-list\n",
        "      tags.append(t.copy())\n",
        "      #print(f'{type(sent)} {type(s)} {type(t)} sent : {s}    and  tag : {t}')\n",
        "      s.clear()\n",
        "      t.clear()\n",
        "    else:\n",
        "      first = False  \n",
        "\n",
        "  s.append(word)\n",
        "  t.append(tag)\n",
        "\n",
        "sents.append(s.copy())\n",
        "tags.append(t.copy())\n",
        "s.clear()\n",
        "t.clear()\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-af3103f781cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Therefore to remove that first addition of empty list we are checking for first sentence and not adding it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentence #'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5291\u001b[0m         \u001b[0;31m# if this fails, go on to more involved attribute setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5292\u001b[0m         \u001b[0;31m# (note that this matches __getattr__, above).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5293\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_names_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5294\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5295\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vXglBy63Uxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(sents), len(tags))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug9K6sQTQ636",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxNJ0PnOX5w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb7NBKI0aR4_",
        "colab_type": "text"
      },
      "source": [
        "## 4) Making sentences.txt and labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6GrBcjwD656",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample for printing\n",
        "\n",
        "for sent in sents:\n",
        "  a = \" \".join(sent)\n",
        "  print(a)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHaHCN6i3b8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Writing sents to sentence.txt\n",
        "\n",
        "with open('sentences.txt','w') as f:\n",
        "  for sent in sents:\n",
        "    line = \" \".join(sent)\n",
        "    f.write(line + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLw1bfMJFUpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample for printing\n",
        "\n",
        "for tag in tags:\n",
        "  a = \" \".join(tag)\n",
        "  print(a)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3BRmJ4wEaQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Writing tags to labels.txt\n",
        "\n",
        "with open('labels.txt','w') as f:\n",
        "  for tag in tags:\n",
        "    line = \" \".join(tag)\n",
        "    f.write(line + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou1LGox0Vu6C",
        "colab_type": "text"
      },
      "source": [
        "Now, we have created 3 small files(train,val and test) from sentences and labels and will be working on them only, as working on small files is fast and we can correct errors(if any) easily without much time wastage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmNlkM2oaZI3",
        "colab_type": "text"
      },
      "source": [
        "## 5) Creating dictionary of words and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN_heeF8WGml",
        "colab_type": "text"
      },
      "source": [
        "Let's first create dictionary of words from sentences and labels in train,test and val file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBJarUyFk6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets create a function: \n",
        "\n",
        "def update_vocab(file_path,vocab):\n",
        "\n",
        "  with open(file_path,'r') as f:\n",
        "\n",
        "    for i,line in enumerate(f):\n",
        "      vocab.update(line.strip().split(' '))\n",
        "\n",
        "    return i+1  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_AXsaJCcjsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from collections import Counter # https://www.journaldev.com/20806/python-counter-python-collections-counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j_m88OHfT6M",
        "colab_type": "text"
      },
      "source": [
        "### 5.1) Creating `Words` Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg-9w89PcJBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "de0c1a5b-d251-409b-e4b9-b92fa9ca03d1"
      },
      "source": [
        "print(\"Words Vocab Building starts :-D \")\n",
        "\n",
        "words = Counter()  # It is basically a dictionary\n",
        "\n",
        "path = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/'\n",
        "\n",
        "train_size = update_vocab(os.path.join(path, 'train/sentences.txt'), words)\n",
        "val_size = update_vocab(os.path.join(path, 'val/sentences.txt'), words)\n",
        "test_size = update_vocab(os.path.join(path, 'test/sentences.txt'), words)\n",
        "\n",
        "print(train_size, val_size, test_size)\n",
        "print(words)\n",
        "\n",
        "print(\"Words Vocab Building successful!!!\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words Vocab Building starts :-D \n",
            "10 10 10\n",
            "Counter({'the': 36, '.': 30, 'of': 21, 'in': 21, 'to': 17, 'and': 13, ',': 12, 'The': 9, 'have': 8, 'at': 8, 'a': 7, \"'s\": 7, 'from': 5, 'was': 5, 'Iran': 5, 'said': 5, 'Iraq': 4, 'troops': 4, 'with': 4, 'as': 4, '\"': 4, 'it': 4, 'on': 4, 'other': 4, 'Wednesday': 4, 'say': 4, 'will': 4, 'that': 3, 'country': 3, 'killed': 3, 'is': 3, 'how': 3, 'parts': 3, 'officials': 3, 'an': 3, 'U.S.': 3, 'has': 3, 'if': 3, 'are': 3, 'oil': 3, 'by': 3, 'Delta': 3, 'for': 3, 'palace': 3, 'not': 3, 'occurred': 3, 'least': 3, 'city': 3, 'fighters': 3, 'Baghdad': 3, 'marched': 2, 'London': 2, 'protest': 2, 'demand': 2, 'British': 2, 'conflict': 2, 'while': 2, 'conference': 2, 'Britain': 2, 'southern': 2, 'ahead': 2, 'conversion': 2, 'week': 2, 'its': 2, 'nuclear': 2, 'plant': 2, 'Iranian': 2, 'they': 2, 'after': 2, 'European': 2, 'which': 2, 'new': 2, 'President': 2, 'were': 2, 'boat': 2, 'Nigeria': 2, 'German': 2, 'firm': 2, 'State': 2, 'Shell': 2, 'attack': 2, 'been': 2, 'where': 2, 'fired': 2, 'mortar': 2, 'shells': 2, 'Mogadishu': 2, 'more': 2, 'than': 2, 'arrived': 2, 'northern': 2, 'Mosul': 2, 'offensive': 2, 'against': 2, 'al': 2, 'Qaida': 2, 'Officials': 2, 'Sunni': 2, 'American': 2, 'Thousands': 1, 'demonstrators': 1, 'through': 1, 'war': 1, 'withdrawal': 1, 'Families': 1, 'soldiers': 1, 'joined': 1, 'protesters': 1, 'who': 1, 'carried': 1, 'banners': 1, 'such': 1, 'slogans': 1, 'Bush': 1, 'Number': 1, 'One': 1, 'Terrorist': 1, 'Stop': 1, 'Bombings': 1, 'They': 1, 'Houses': 1, 'Parliament': 1, 'rally': 1, 'Hyde': 1, 'Park': 1, 'Police': 1, 'put': 1, 'number': 1, 'marchers': 1, '10,000': 1, 'organizers': 1, 'claimed': 1, '1,00,000': 1, 'comes': 1, 'eve': 1, 'annual': 1, 'ruling': 1, 'Labor': 1, 'Party': 1, 'English': 1, 'seaside': 1, 'resort': 1, 'Brighton': 1, 'party': 1, 'divided': 1, 'over': 1, 'participation': 1, 'continued': 1, 'deployment': 1, '8,500': 1, 'march': 1, 'came': 1, 'anti-war': 1, 'protests': 1, 'today': 1, 'cities': 1, 'including': 1, 'Rome': 1, 'Paris': 1, 'Madrid': 1, 'International': 1, 'Atomic': 1, 'Energy': 1, 'Agency': 1, 'hold': 1, 'second': 1, 'day': 1, 'talks': 1, 'Vienna': 1, 'respond': 1, 'resumption': 1, 'low-level': 1, 'uranium': 1, 'this': 1, 'restarted': 1, 'process': 1, 'Isfahan': 1, 'expect': 1, 'get': 1, 'access': 1, 'sealed': 1, 'sensitive': 1, 'IAEA': 1, 'surveillance': 1, 'system': 1, 'begins': 1, 'functioning': 1, 'step': 1, 'allow': 1, 'facility': 1, 'operate': 1, 'full': 1, 'capacity': 1, 'Union': 1, 'backing': 1, 'threatened': 1, 'refer': 1, 'U.N.': 1, 'Security': 1, 'Council': 1, 'could': 1, 'impose': 1, 'sanctions': 1, 'finds': 1, 'Tehran': 1, 'violated': 1, 'Nuclear': 1, 'Non-Proliferation': 1, 'treaty': 1, 'Mahmoud': 1, 'Ahmadinejad': 1, 'Tuesday': 1, 'incentives': 1, 'aimed': 1, 'persuading': 1, 'end': 1, 'fuel': 1, 'program': 1, 'insult': 1, 'nation': 1, 'Two': 1, 'Germans': 1, 'four': 1, 'Nigerian': 1, 'workers': 1, 'kidnapped': 1, 'armed': 1, 'militants': 1, 'during': 1, 'raid': 1, 'oil-rich': 1, 'region': 1, 'An': 1, 'official': 1, 'Bilfinger': 1, 'Berger': 1, 'Thomas': 1, 'Horbach': 1, 'gunmen': 1, 'stopped': 1, 'supply': 1, 'sailed': 1, 'Bayelsa': 1, 'inspect': 1, 'offshore': 1, 'field': 1, 'owned': 1, 'Royal-Dutch': 1, 'works': 1, 'sub-contractor': 1, 'Militant': 1, 'groups': 1, 'frequently': 1, 'operations': 1, 'Niger': 1, 'social': 1, 'services': 1, 'better': 1, 'job': 1, 'opportunities': 1, 'multinational': 1, 'companies': 1, 'Poor': 1, 'residents': 1, 'often': 1, 'complain': 1, 'cheated': 1, 'out': 1, 'huge': 1, 'riches': 1, 'extracted': 1, 'their': 1, 'tribal': 1, 'lands': 1, '-': 1, 'bulk': 1, '2.3': 1, 'million': 1, 'barrels': 1, 'petroleum': 1, 'pumped': 1, 'daily': 1, 'Suspected': 1, 'Islamist': 1, 'rebels': 1, 'used': 1, 'Somalia': 1, 'interim': 1, 'Abdullahi': 1, 'Yusuf': 1, 'Ahmad': 1, 'It': 1, 'immediately': 1, 'clear': 1, 'president': 1, 'when': 1, 'or': 1, 'anyone': 1, 'hurt': 1, 'Local': 1, 'news': 1, 'reports': 1, 'five': 1, 'hit': 1, 'compound': 1, 'mortars': 1, 'elsewhere': 1, 'attacks': 1, 'government': 1, 'go': 1, 'reconciliation': 1, '1,300': 1, 'Somali': 1, 'elders': 1, 'warlords': 1, 'politicians': 1, 'invited': 1, 'Iraqi': 1, 'military': 1, 'tanks': 1, 'many': 1, 'Arab': 1, 'Kurdish': 1, 'bombings': 1, 'last': 1, '34': 1, 'people': 1, 'wounded': 1, '200': 1, 'commanders': 1, 'explained': 1, 'forces': 1, 'participate': 1, 'fled': 1, 'successful': 1, 'campaigns': 1, 'them': 1, 'Anbar': 1, 'province': 1, 'provinces': 1, 'largest': 1, 'north': 1, 'long': 1, 'stronghold': 1, 'militant': 1, 'In': 1, 'violence': 1, 'one': 1, 'soldier': 1, 'patrol': 1, 'Sunday': 1, 'Egyptian': 1, 'police': 1, 'arrested': 1, '16': 1, 'members': 1, 'opposition': 1, 'Muslim': 1, 'Brotherhood': 1, 'prepare': 1, 'parliamentary': 1, 'runoff': 1, 'elections': 1, 'Saturday': 1, 'arrests': 1, 'Friday': 1, 'Alexandria': 1})\n",
            "Words Vocab Building successful!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12d52hcUfZFx",
        "colab_type": "text"
      },
      "source": [
        "### 5.2) Creating `Tags` Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed4G1GhsdO1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0ee8a6d1-6efd-4e35-a421-8c40bb6b6d1a"
      },
      "source": [
        "print(\"Tags Vocab Building starts :-D \")\n",
        "\n",
        "tags = Counter()  # It is basically a dictionary\n",
        "\n",
        "path = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/'\n",
        "\n",
        "train_size = update_vocab(os.path.join(path, 'train/labels.txt'), tags)\n",
        "val_size = update_vocab(os.path.join(path, 'val/labels.txt'), tags)\n",
        "test_size = update_vocab(os.path.join(path, 'test/labels.txt'), tags)\n",
        "\n",
        "print(train_size, val_size, test_size)\n",
        "print(tags)\n",
        "\n",
        "print(\"Tags Vocab Building successful!!!\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tags Vocab Building starts :-D \n",
            "10 10 10\n",
            "Counter({'O': 580, 'B-geo': 29, 'B-gpe': 26, 'I-org': 16, 'B-org': 12, 'B-tim': 8, 'I-per': 6, 'I-geo': 5, 'B-per': 4, 'B-art': 1, 'I-art': 1})\n",
            "Tags Vocab Building successful!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5WRBZrqhyIh",
        "colab_type": "text"
      },
      "source": [
        "### 5.3) Keeping Most Frequent Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkUkFQ01i6dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keeping only most frequent words\n",
        "words = [token for token,count in words.items() if count>=1]\n",
        "tags =  [token for token,count in tags.items() if count>=1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0rZU2ejV4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEKKr1BpjgNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d7468b8b-bced-4041-d332-007198a54205"
      },
      "source": [
        "tags"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-per',\n",
              " 'I-geo',\n",
              " 'B-org',\n",
              " 'I-org',\n",
              " 'B-tim',\n",
              " 'B-art',\n",
              " 'I-art',\n",
              " 'I-per']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If21hz8Sjmih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper parameters for the vocab\n",
        "\n",
        "PAD_WORD = '<pad>'\n",
        "PAD_TAG = 'O'\n",
        "UNK_WORD = 'UNK'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFZjX8VMj4dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add pad tokens\n",
        "if PAD_WORD not in words: words.append(PAD_WORD)\n",
        "if PAD_TAG not in tags: tags.append(PAD_TAG)\n",
        "\n",
        "# add word for unknown words \n",
        "words.append(UNK_WORD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoP-FpYEkBsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLYtsWa5kKY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9WCiEVxkk7j",
        "colab_type": "text"
      },
      "source": [
        "### 5.4) Saving words and tags to text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXy9blbhkQ0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_file(file_path,vocab):\n",
        "\n",
        "  with open(file_path,'w') as f:\n",
        "\n",
        "    for tok in vocab:\n",
        "      f.write(tok + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW0pObJslrx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYTvIUpPlesd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0afba16f-c417-42ec-dd24-b29abf27d986"
      },
      "source": [
        "# For words.txt \n",
        "\n",
        "print(\"Making words.txt file \\n\")\n",
        "save_to_file(os.path.join(path,'words.txt'),words)\n",
        "print('done')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making words.txt file \n",
            "\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN1dJzMTmEl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "172b9733-00cf-4a01-ab98-ba04d8766e0e"
      },
      "source": [
        "# For tags.txt \n",
        "\n",
        "print(\"Making tags.txt file \\n\")\n",
        "save_to_file(os.path.join(path,'tags.txt'),tags)\n",
        "print('done')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making tags.txt file \n",
            "\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qg8kV3WoeVy",
        "colab_type": "text"
      },
      "source": [
        "### 5.5) Creating json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1Z6Lhqp6r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOqp7lIOmRZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_json(file_path,d):\n",
        "\n",
        "  with open(file_path, 'w') as f:\n",
        "    d = {k: v for k, v in d.items()}\n",
        "    json.dump(d, f, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-JVZ_pOo6N_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save datasets properties in json file\n",
        "\n",
        "path = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/small/'\n",
        "\n",
        "sizes = {\n",
        "    'train_size': train_size,\n",
        "    'dev_size': val_size,\n",
        "    'test_size': test_size,\n",
        "    'vocab_size': len(words),\n",
        "    'number_of_tags': len(tags),\n",
        "    'pad_word': PAD_WORD,\n",
        "    'pad_tag': PAD_TAG,\n",
        "    'unk_word': UNK_WORD\n",
        "}\n",
        "\n",
        "save_to_json(os.path.join(path, 'dataset_params.json'),sizes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcSc2bwopCPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6b886d69-1721-459c-ff5c-07a61a9f7d7a"
      },
      "source": [
        "# Logging sizes\n",
        "\n",
        "to_print = \"\\n\".join(\"- {}: {}\".format(k, v) for k, v in sizes.items())\n",
        "print(\"Characteristics of the dataset:\\n{}\".format(to_print))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characteristics of the dataset:\n",
            "- train_size: 10\n",
            "- dev_size: 10\n",
            "- test_size: 10\n",
            "- vocab_size: 369\n",
            "- number_of_tags: 11\n",
            "- pad_word: <pad>\n",
            "- pad_tag: O\n",
            "- unk_word: UNK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf7H0dy0qOYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional Lstm + CRF.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1LpxWKzIwRF2LP8iKbSLxBSBpKLHp0xki",
      "authorship_tag": "ABX9TyNU4z3fFRRhd1ID40gV0yLF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdGLlbTuaHH4",
        "colab_type": "text"
      },
      "source": [
        "# Bidirectional LSTM + CRF\n",
        "\n",
        "If you are new to this post, then please refer to [Model Basics](https://github.com/akash1309/Named-Entity-Recognition/blob/master/Model_Basics.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx7Q18mNakfk",
        "colab_type": "text"
      },
      "source": [
        "For this section, we will see a full, complicated example of a Bi-LSTM\n",
        "Conditional Random Field for named-entity recognition. The LSTM tagger\n",
        "above is typically sufficient for part-of-speech tagging, but a sequence\n",
        "model like the CRF is really essential for strong performance on NER.\n",
        "Familiarity with CRF's is assumed. Although this name sounds scary, all\n",
        "the model is is a CRF but where an LSTM provides the features.  Recall that the CRF computes a conditional probability. Let\n",
        "$y$ be a tag sequence and $x$ an input sequence of words.\n",
        "Then we compute\n",
        "\n",
        "\\begin{align}P(y|x) = \\frac{\\exp{(\\text{Score}(x, y)})}{\\sum_{y'} \\exp{(\\text{Score}(x, y')})}\\end{align}\n",
        "\n",
        "Where the score is determined by defining some log potentials\n",
        "$\\log \\psi_i(x,y)$ such that\n",
        "\n",
        "\\begin{align}\\text{Score}(x,y) = \\sum_i \\log \\psi_i(x,y)\\end{align}\n",
        "\n",
        "To make the partition function tractable, the potentials must look only\n",
        "at local features.\n",
        "\n",
        "In the Bi-LSTM CRF, we define two kinds of potentials: emission and\n",
        "transition. The emission potential for the word at index $i$ comes\n",
        "from the hidden state of the Bi-LSTM at timestep $i$. The\n",
        "transition scores are stored in a $|T|x|T|$ matrix\n",
        "$\\textbf{P}$, where $T$ is the tag set. In my\n",
        "implementation, $\\textbf{P}_{j,k}$ is the score of transitioning\n",
        "to tag $j$ from tag $k$. So:\n",
        "\n",
        "\\begin{align}\\text{Score}(x,y) = \\sum_i \\log \\psi_\\text{EMIT}(y_i \\rightarrow x_i) + \\log \\psi_\\text{TRANS}(y_{i-1} \\rightarrow y_i)\\end{align}\n",
        "\n",
        "\\begin{align}= \\sum_i h_i[y_i] + \\textbf{P}_{y_i, y_{i-1}}\\end{align}\n",
        "\n",
        "where in this second expression, we think of the tags as being assigned\n",
        "unique non-negative indices.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfHt-C66Y93m",
        "colab_type": "code",
        "outputId": "27afe4a0-845c-4b4b-8387-ee6a670ad763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f84578cb730>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUytgB4B7jm",
        "colab_type": "code",
        "outputId": "29d3e329-c569-4500-e9de-b68b4ec476a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "is_gpu = torch.cuda.is_available()\n",
        "is_gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFMdpGRKaxHH",
        "colab_type": "text"
      },
      "source": [
        "Helper functions to make the code more readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIUHOsg2arqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def argmax(vec):\n",
        "  # return the argmax as a python int\n",
        "  _, idx = torch.max(vec, 1)\n",
        "  return idx.item()\n",
        "\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "  idxs = [to_ix[w] for w in seq]\n",
        "  return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "  max_score = vec[0, argmax(vec)]\n",
        "  max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "  return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6yaSW3ya3T-",
        "colab_type": "text"
      },
      "source": [
        "Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YnnCmo6a0cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "    super(BiLSTM_CRF, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.tag_to_ix = tag_to_ix\n",
        "    self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "    self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,num_layers=1, bidirectional=True)\n",
        "\n",
        "    # Maps the output of the LSTM into tag space.\n",
        "    self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "    # Matrix of transition parameters.  Entry i,j is the score of\n",
        "    # transitioning *to* i *from* j.\n",
        "    self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "    # These two statements enforce the constraint that we never transfer\n",
        "    # to the start tag and we never transfer from the stop tag\n",
        "    self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "    self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return (torch.randn(2, 1, self.hidden_dim // 2),torch.randn(2, 1, self.hidden_dim // 2))\n",
        "\n",
        "\n",
        "  def _forward_alg(self, feats):\n",
        "    # Do the forward algorithm to compute the partition function\n",
        "    init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "    # START_TAG has all of the score.\n",
        "    init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "    # Wrap in a variable so that we will get automatic backprop\n",
        "    forward_var = init_alphas\n",
        "\n",
        "    # Iterate through the sentence\n",
        "    for feat in feats:\n",
        "      alphas_t = []  # The forward tensors at this timestep\n",
        "      for next_tag in range(self.tagset_size):\n",
        "        # broadcast the emission score: it is the same regardless of\n",
        "        # the previous tag\n",
        "        emit_score = feat[next_tag].view(\n",
        "            1, -1).expand(1, self.tagset_size)\n",
        "        # the ith entry of trans_score is the score of transitioning to\n",
        "        # next_tag from i\n",
        "        trans_score = self.transitions[next_tag].view(1, -1)\n",
        "        # The ith entry of next_tag_var is the value for the\n",
        "        # edge (i -> next_tag) before we do log-sum-exp\n",
        "        next_tag_var = forward_var + trans_score + emit_score\n",
        "        # The forward variable for this tag is log-sum-exp of all the\n",
        "        # scores.\n",
        "        alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "      forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "    alpha = log_sum_exp(terminal_var)\n",
        "    return alpha\n",
        "\n",
        "  def _get_lstm_features(self, sentence):\n",
        "    self.hidden = self.init_hidden()\n",
        "    embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "    lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "    lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "    lstm_feats = self.hidden2tag(lstm_out)\n",
        "    return lstm_feats\n",
        "\n",
        "  def _score_sentence(self, feats, tags):\n",
        "    # Gives the score of a provided tag sequence\n",
        "    score = torch.zeros(1)\n",
        "    tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "    for i, feat in enumerate(feats):\n",
        "      score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "    score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "    return score\n",
        "\n",
        "  def _viterbi_decode(self, feats):\n",
        "    backpointers = []\n",
        "\n",
        "    # Initialize the viterbi variables in log space\n",
        "    init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "    init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "    # forward_var at step i holds the viterbi variables for step i-1\n",
        "    forward_var = init_vvars\n",
        "    for feat in feats:\n",
        "      bptrs_t = []  # holds the backpointers for this step\n",
        "      viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "      for next_tag in range(self.tagset_size):\n",
        "        # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "        # previous step, plus the score of transitioning\n",
        "        # from tag i to next_tag.\n",
        "        # We don't include the emission scores here because the max\n",
        "        # does not depend on them (we add them in below)\n",
        "        next_tag_var = forward_var + self.transitions[next_tag]\n",
        "        best_tag_id = argmax(next_tag_var)\n",
        "        bptrs_t.append(best_tag_id)\n",
        "        viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "      # Now add in the emission scores, and assign forward_var to the set\n",
        "      # of viterbi variables we just computed\n",
        "      forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "      backpointers.append(bptrs_t)\n",
        "\n",
        "    # Transition to STOP_TAG\n",
        "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "    best_tag_id = argmax(terminal_var)\n",
        "    path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "    # Follow the back pointers to decode the best path.\n",
        "    best_path = [best_tag_id]\n",
        "    for bptrs_t in reversed(backpointers):\n",
        "      best_tag_id = bptrs_t[best_tag_id]\n",
        "      best_path.append(best_tag_id)\n",
        "    # Pop off the start tag (we dont want to return that to the caller)\n",
        "    start = best_path.pop()\n",
        "    assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "    best_path.reverse()\n",
        "    return path_score, best_path\n",
        "\n",
        "  def neg_log_likelihood(self, sentence, tags):\n",
        "    feats = self._get_lstm_features(sentence)\n",
        "    forward_score = self._forward_alg(feats)\n",
        "    gold_score = self._score_sentence(feats, tags)\n",
        "    return forward_score - gold_score\n",
        "\n",
        "  def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "    # Get the emission scores from the BiLSTM\n",
        "    lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "    # Find the best path, given the features.\n",
        "    score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "    return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpH_8X95bAj9",
        "colab_type": "text"
      },
      "source": [
        "Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Og9igNcwV2",
        "colab_type": "code",
        "outputId": "d6db3dba-1931-4786-93e3-9b3c4bf0a5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# For words\n",
        "\"\"\"\n",
        "word_filepath = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/big/words.txt'\n",
        "word_to_ix = {}\n",
        "with open(word_filepath,'r') as f:\n",
        "\n",
        "  for i,word in enumerate(set(f.read().splitlines())):\n",
        "    word_to_ix[word] = i   # Because first 2 indices are stored for padding and unknown character\n",
        "\n",
        "#word_to_ix['<pad>'] = 0  # padding\n",
        "#word_to_ix['UNK'] = 1    # unknown\n",
        "\n",
        "ix_to_word = {index: word for word, index in word_to_ix.items()}\n",
        "print(len(word_to_ix))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nword_filepath = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/big/words.txt'\\nword_to_ix = {}\\nwith open(word_filepath,'r') as f:\\n\\n  for i,word in enumerate(set(f.read().splitlines())):\\n    word_to_ix[word] = i   # Because first 2 indices are stored for padding and unknown character\\n\\n#word_to_ix['<pad>'] = 0  # padding\\n#word_to_ix['UNK'] = 1    # unknown\\n\\nix_to_word = {index: word for word, index in word_to_ix.items()}\\nprint(len(word_to_ix))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lHVshgdAwu",
        "colab_type": "code",
        "outputId": "c10c04de-4db8-4213-d86f-6a106f7232cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# for tags.txt\n",
        "\"\"\"\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tags_filepath = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/big/tags.txt'\n",
        "tag_to_ix = {}\n",
        "\n",
        "with open(tags_filepath,'r') as f:\n",
        "  for i,word in enumerate(set(f.read().splitlines())):\n",
        "    tag_to_ix[word] = i\n",
        "tag_to_ix[START_TAG] = len(tag_to_ix)\n",
        "tag_to_ix[STOP_TAG] = len(tag_to_ix)\n",
        "\n",
        "ix_to_tag = {index: word for word, index in tag_to_ix.items()}\n",
        "print(len(tag_to_ix))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSTART_TAG = \"<START>\"\\nSTOP_TAG = \"<STOP>\"\\ntags_filepath = \\'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/big/tags.txt\\'\\ntag_to_ix = {}\\n\\nwith open(tags_filepath,\\'r\\') as f:\\n  for i,word in enumerate(set(f.read().splitlines())):\\n    tag_to_ix[word] = i\\ntag_to_ix[START_TAG] = len(tag_to_ix)\\ntag_to_ix[STOP_TAG] = len(tag_to_ix)\\n\\nix_to_tag = {index: word for word, index in tag_to_ix.items()}\\nprint(len(tag_to_ix))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySYX8t7Ma9if",
        "colab_type": "code",
        "outputId": "1ea918b8-7671-43b3-a283-296f568f574a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 50\n",
        "\n",
        "# Make up some training data\n",
        "sent_file = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/big/sentences.txt'\n",
        "label_file = 'drive/My Drive/Pytorch_DataSet/Named Entity Recognition/big/labels.txt'\n",
        "sentences = []\n",
        "with open(sent_file,'r') as f:\n",
        "  txt = f.read().splitlines()\n",
        "\n",
        "for sent in txt:\n",
        "  sentences.append(sent)\n",
        "\n",
        "print(len(sentences))\n",
        "\n",
        "labels = []\n",
        "with open(label_file,'r') as f:\n",
        "  txt = f.read().splitlines()\n",
        "\n",
        "for lab in txt:\n",
        "  labels.append(lab)\n",
        "\n",
        "print(len(labels))\n",
        "print(sentences[0])\n",
        "print(labels[0])\n",
        "\n",
        "data = [(sentences[i].split(), labels[i].split()) for i in range(0, len(sentences))]\n",
        "# For now lets take only 1000 sentences\n",
        "\n",
        "word_to_ix = {}\n",
        "tag_to_ix = {}\n",
        "\n",
        "for sentence, tags in data[:1010]:\n",
        "  for word in sentence:\n",
        "    if word not in word_to_ix:\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "  for lab in tags:\n",
        "    if lab not in tag_to_ix:\n",
        "      tag_to_ix[lab] = len(tag_to_ix)\n",
        "      \n",
        "ix_to_word = {index: word for word, index in word_to_ix.items()}\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix[START_TAG] = len(tag_to_ix)\n",
        "tag_to_ix[STOP_TAG] = len(tag_to_ix)\n",
        "\n",
        "ix_to_tag = {index: word for word, index in tag_to_ix.items()}\n",
        "print(len(word_to_ix),len(tag_to_ix))\n",
        "\n",
        "training_data = data[:1000]\n",
        "testing_data = data[1000:1010]\n",
        "print(len(training_data))\n",
        "#print(training_set[:2]) \n",
        "print(type(training_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47959\n",
            "47959\n",
            "Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
            "O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
            "4675 19\n",
            "1000\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWptc-mFbGNh",
        "colab_type": "code",
        "outputId": "54cccbc4-09dc-4342-f731-a280afab6d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_CRF(\n",
              "  (word_embeds): Embedding(4675, 50)\n",
              "  (lstm): LSTM(50, 25, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=50, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf8ggaGtbHDt",
        "colab_type": "code",
        "outputId": "7331b7e1-61c3-4f4f-95c2-285e13dc72e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "optimizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    lr: 0.01\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0.0001\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSvAoGPZbLXg",
        "colab_type": "code",
        "outputId": "992a9972-66fa-46d7-f0b2-ef614016b6c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Check predictions before training\n",
        "with torch.no_grad():\n",
        "  precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "  precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
        "  print(model(precheck_sent))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor(48.6656), [4, 13, 3, 11, 1, 14, 15, 1, 14, 15, 1, 14, 15, 1, 14, 4, 13, 3, 11, 3, 11, 10, 9, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MLOP5S8bPBy",
        "colab_type": "code",
        "outputId": "c5b27db5-2b5f-4fb3-ede5-0debe2f6d8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "losses = []\n",
        "\n",
        "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
        "for epoch in range(30):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "  tracker = 0\n",
        "  for sentence, tags in training_data:\n",
        "    tracker += 1\n",
        "    # Step 1. Remember that Pytorch accumulates gradients.\n",
        "    # We need to clear them out before each instance\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Step 2. Get our inputs ready for the network, that is,\n",
        "    # turn them into Tensors of word indices.\n",
        "    sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "    targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "    \n",
        "    # Step 3. Run our forward pass.\n",
        "    loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "    losses.append(loss.item())\n",
        "    if(tracker%500 == 0):\n",
        "      print(f'Epochs : {epoch}  Loss Values : {loss.item()}')\n",
        "    # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "    # calling optimizer.step()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs : 0  Loss Values : 3.600341796875\n",
            "Epochs : 0  Loss Values : 1.7866630554199219\n",
            "Epochs : 1  Loss Values : 2.4691009521484375\n",
            "Epochs : 1  Loss Values : 3.413646697998047\n",
            "Epochs : 2  Loss Values : 1.2697906494140625\n",
            "Epochs : 2  Loss Values : 1.7527084350585938\n",
            "Epochs : 3  Loss Values : 0.75506591796875\n",
            "Epochs : 3  Loss Values : 0.8287887573242188\n",
            "Epochs : 4  Loss Values : 0.5165252685546875\n",
            "Epochs : 4  Loss Values : 0.480316162109375\n",
            "Epochs : 5  Loss Values : 0.3390350341796875\n",
            "Epochs : 5  Loss Values : 2.0801925659179688\n",
            "Epochs : 6  Loss Values : 0.2626953125\n",
            "Epochs : 6  Loss Values : 0.30590057373046875\n",
            "Epochs : 7  Loss Values : 0.199493408203125\n",
            "Epochs : 7  Loss Values : 0.24738311767578125\n",
            "Epochs : 8  Loss Values : 0.20855712890625\n",
            "Epochs : 8  Loss Values : 0.21897125244140625\n",
            "Epochs : 9  Loss Values : 0.1334228515625\n",
            "Epochs : 9  Loss Values : 0.07977294921875\n",
            "Epochs : 10  Loss Values : 0.167388916015625\n",
            "Epochs : 10  Loss Values : 0.15367889404296875\n",
            "Epochs : 11  Loss Values : 0.16546630859375\n",
            "Epochs : 11  Loss Values : 0.1247100830078125\n",
            "Epochs : 12  Loss Values : 0.079498291015625\n",
            "Epochs : 12  Loss Values : 0.06868743896484375\n",
            "Epochs : 13  Loss Values : 0.045623779296875\n",
            "Epochs : 13  Loss Values : 0.14611053466796875\n",
            "Epochs : 14  Loss Values : 0.037078857421875\n",
            "Epochs : 14  Loss Values : 0.08429718017578125\n",
            "Epochs : 15  Loss Values : 0.0567626953125\n",
            "Epochs : 15  Loss Values : 0.08133697509765625\n",
            "Epochs : 16  Loss Values : 0.100921630859375\n",
            "Epochs : 16  Loss Values : 0.0549774169921875\n",
            "Epochs : 17  Loss Values : 0.0604248046875\n",
            "Epochs : 17  Loss Values : 0.041961669921875\n",
            "Epochs : 18  Loss Values : 0.0626220703125\n",
            "Epochs : 18  Loss Values : 0.047607421875\n",
            "Epochs : 19  Loss Values : 0.101165771484375\n",
            "Epochs : 19  Loss Values : 0.0594482421875\n",
            "Epochs : 20  Loss Values : 0.1075439453125\n",
            "Epochs : 20  Loss Values : 0.0195465087890625\n",
            "Epochs : 21  Loss Values : 0.045196533203125\n",
            "Epochs : 21  Loss Values : 0.1200714111328125\n",
            "Epochs : 22  Loss Values : 0.05438232421875\n",
            "Epochs : 22  Loss Values : 0.0130615234375\n",
            "Epochs : 23  Loss Values : 0.118804931640625\n",
            "Epochs : 23  Loss Values : 0.014678955078125\n",
            "Epochs : 24  Loss Values : 0.04180908203125\n",
            "Epochs : 24  Loss Values : 0.022247314453125\n",
            "Epochs : 25  Loss Values : 0.036163330078125\n",
            "Epochs : 25  Loss Values : 0.03936767578125\n",
            "Epochs : 26  Loss Values : 0.047576904296875\n",
            "Epochs : 26  Loss Values : 0.0398101806640625\n",
            "Epochs : 27  Loss Values : 0.0250244140625\n",
            "Epochs : 27  Loss Values : 0.0194854736328125\n",
            "Epochs : 28  Loss Values : 0.033294677734375\n",
            "Epochs : 28  Loss Values : 0.010345458984375\n",
            "Epochs : 29  Loss Values : 0.038482666015625\n",
            "Epochs : 29  Loss Values : 0.0211639404296875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDavK3hip7iz",
        "colab_type": "code",
        "outputId": "92d3117c-d138-4a02-bf03-0f07f97bce3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "# Check predictions after training\n",
        "with torch.no_grad():\n",
        "  for sent, tag in testing_data:\n",
        "    precheck_sent = prepare_sequence(sent, word_to_ix)\n",
        "    a = model(precheck_sent)\n",
        "    b = [ix_to_tag[t] for t in a[1]]\n",
        "    print(f'Predicted Labels : {b}')\n",
        "    print(f'Actual Labels :    {tag}')\n",
        "    print('\\n\\n')  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O']\n",
            "Actual Labels :    ['O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O']\n",
            "Actual Labels :    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['B-per', 'I-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Actual Labels :    ['O', 'O', 'B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Actual Labels :    ['O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O']\n",
            "Actual Labels :    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'B-tim', 'I-tim', 'O']\n",
            "Actual Labels :    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'B-org', 'I-org', 'I-org', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Actual Labels :    ['O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'B-geo', 'O', 'O']\n",
            "Actual Labels :    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'B-geo', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Actual Labels :    ['O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n",
            "Predicted Labels : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Actual Labels :    ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnBtIV2f7ym8",
        "colab_type": "text"
      },
      "source": [
        "Model Efficiency can be increased with hyperparameter tuning.\n",
        "- No. of epochs \n",
        "- No. of hidden layers\n",
        "- No. of hidden dimension\n",
        "- Embedding size\n",
        "- Learning Rate\n",
        "- Other Features "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad8-ePY4Xnyf",
        "colab_type": "text"
      },
      "source": [
        "Now, we will be explaining different parts of the above code and logic."
      ]
    }
  ]
}